{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Housing Price Predication using Linear Regression\n",
    "\n",
    "> ### Machine Learning Assignments of Linear Regression for Housing Price\n",
    "\n",
    "In this Project we will make Linear Regression model for simple Housing prizing problem using Python. In this Project we are not using any machine learning liberary ,but insteed we develop function by self. This way we can learn very basic way to implement machine learning. \n",
    "\n",
    "In this project first we are developing machine learning function for linear regression named as LinearRegression(). In Next step we Load training data in function to train and then we check how training being done. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Useful Liberary :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from housingdata import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Basic Information for Naming Convention Used :\n",
    "- X = Features,\n",
    "- Y = Resposes,\n",
    "- W = weights - Learning Parameter,\n",
    "- b = bias - Learning Parameter\n",
    "- α = Learning Rate,\n",
    "- m = Training set size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Learning Parameter :\n",
    "\n",
    "Here, we initialize learning parameter W and b."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(n_x,method):   \n",
    "    if method == \"Linear\":\n",
    "        W = np.zeros((1,n_x))\n",
    "        b = 0\n",
    "    elif method == \"Logistic\":\n",
    "        W = np.zeros((1,n_x))\n",
    "        b = 0\n",
    "    else :\n",
    "        print \"Error : Define method in initialize parameter\"\n",
    "        return W, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Normalize : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_normalization(X):\n",
    "    (row, col) = X.shape\n",
    "    for f in range(1,row):\n",
    "        X[f,:] = (X[f,:]- min(X[f,:].T))/(max(X[f,:].T)- min(X[f,:].T))\n",
    "        assert(X.shape==(row,col)),\"Error in size match : feature_normalization\"\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyponthsis and Cost Function :\n",
    "> h(X) = b + W(1) * X(1) + W(2) * X(2) + W(3) * X(3) ...\n",
    "> Cost_Function = ( h(X) - Y )**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function(X, Y, W, b, method):\n",
    "    ## where X shape is (input_size, no_examples)\n",
    "    (n,m) = X.shape\n",
    "    if method == \"Linear\":\n",
    "        hyponthsis_function = np.dot(W,X) + b\n",
    "        cost = np.square(hyponthsis_function - Y)\n",
    "        error = np.sum(cost /(m),axis=1)\n",
    "    elif method == \"Logistic\":\n",
    "        Z = np.dot(W,X) + b\n",
    "        hyponthsis_function = 1/(1+exp(-Z))\n",
    "        cost = - np.dot(Y,np.log(hyponthsis_function).T) - np.dot(1 - Y,np.log(1 - hyponthsis_function).T) \n",
    "        error = np.sum(cost /(m),axis=1)\n",
    "    else:\n",
    "        print \"Error In Cost Function : No method Found\"\n",
    "    return hyponthsis_function, cost, error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Decent :\n",
    "> grad J = (1/2) * (h(X) - Y)\n",
    " \n",
    ">  b := b - (α / 2 * m) (**∑** (h(X) - Y) * X(i))\n",
    " \n",
    ">  W(i) := w(i) - (α / 2 * m) (**∑** (h(X) - Y) * X(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X, Y, W, b, itertions, learning_rate, method):\n",
    "    (n,m) = X.shape\n",
    "    for iteration in range(itertions):\n",
    "        if method == \"Linear\":\n",
    "            dJ = np.dot(W,X) + b - Y\n",
    "            db = np.sum(dJ, axis=0)/(2*m)\n",
    "            dW = np.sum(np.dot(dJ,X.T), axis=0)/(2*m)\n",
    "        elif method == \"Logistic\":\n",
    "            Z = np.dot(W,X) + b\n",
    "            dJ = Y - Z\n",
    "            db = np.sum(dJ, axis=0)/m\n",
    "            dW = np.sum(np.dot(dJ,X.T), axis=0)/m\n",
    "        else:\n",
    "            print \"Error in gradient descent: No method Found\"\n",
    "        W = W - learning_rate * dW\n",
    "        b = b - learning_rate * db\n",
    "    #print dJ.shape\n",
    "    assert(dJ.shape == (W.shape[0],X.shape[1]))\n",
    "    assert(db.shape == b.shape)\n",
    "    assert(dW.shape == W.shape)\n",
    "    return W,b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By implementing this function we make LinearRegression function and training to get optimal Learning Parameters b and W."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization Function :  \n",
    "\n",
    "I have implemented simple visualization function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualization(x, y, hf):\n",
    "    fig, handle = plt.subplots()\n",
    "    handle.plot(x, y, \"yo\", x, hf, \"--k\")\n",
    "    #handle.plot(x, hf, color='red')\n",
    "    #handle.scatter(x, y)\n",
    "    fig.show()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Linear Regression function : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression(X, Y, itertions, learning_rate, method = \"Linear\"):\n",
    "    (row, col) = X.shape\n",
    "    (W, b) = initialize_parameters(row,method)\n",
    "    X = feature_normalization(X)\n",
    "    (W,b) = gradient_descent(X, Y, W, b, itertions, learning_rate, method)\n",
    "    hyponthsis_function, cost, error = cost_function(X, Y, W, b, method)\n",
    "    return hyponthsis_function, error, W, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Reading and Function Call : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y, Xv, Yv = housingPrice()\n",
    "hyponthsis_function, error, W, b = linear_regression(X, Y, itertions=1000, learning_rate=0.5, method=\"Linear\")\n",
    "print Y[0,5], hyponthsis_function[0,5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Trained model : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Xv[1,:].T\n",
    "x = np.array(x)\n",
    "x = x.flatten()\n",
    "y = Yv.T\n",
    "y = np.array(y)\n",
    "y = y.flatten()\n",
    "hf, error, W, b = linear_regression(Xv, Yv, itertions=100, learning_rate=0.5, method=\"Linear\")\n",
    "hf = np.array(hf)\n",
    "hf = hf.flatten()\n",
    "#print X,X.shape,hyponthsis_function.shape\n",
    "A = visualization(x, y, hf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Way we can sucessfully predict Housing price using machine learning "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
